  HashMap - java.util.HashMap class is a Hashing based implementation. 
  We have key-value pair<key,value>, 
  Unsynchronized - ie multiple threads can access it simultaneously.
  
  Key points :-
  
  1. HashMap does not maintain the order. not by key or value, if we need ordered key then we need to use TreeMap
  2. Complexity - get/put/containsKey() operations are O(1) in average case but we can't guarantee that since its all depend on 
  computation
  
  
  Features :-
  
  		Hashing is a technique for converting large string into small string. A shorter value helps in indexing and faster searches.
  
  		HashSet also uses HashMap internally- it internally use link list to store key-value pair
  
  		HashMap doesn’t allow duplicate keys but allows duplicate values. That means A single key can’t contain more than 1 value but 
  		more than 1 key can contain a single value.
  
  		HashMap allows null key also but only once and multiple null values.
  
  		This class makes no guarantees as to the order of the map; in particular, it does not guarantee that the order will remain 
  		constant over time. It is roughly similar to HashTable but is unsynchronized.
  
  		HashMap extends an abstract class AbstractMap which also provides an incomplete implementation of Map interface.
  
  		It also implements Cloneable and Serializable interface. K and V in the above definition represent Key and Value respectively. 
  		
  		HashMap is an unordered collection. It does not guarantee any specific order of the elements.
  		
		HashMap is not thread-safe. You must explicitly synchronize concurrent modifications to the HashMap. Or you can use 
		Collections.synchronizedMap(hashMap) 	to get the synchronized version of HashMap.
		
		A value can be retrieved only using the associated key.
		
		HashMap stores only object references. So primitives must be used with their corresponding wrapper classes. Such as int
		will be stored as Integer.
 
  
  
  Internal Structure of HashMap :-

	HashMap works on principle of hashing. 
	
	Hashing is a way to assigning a unique code for any variable/object after applying any 
	formula/algorithm on its properties. 
	
	Each object in java has it’s hash code in such a way that two equal objects must produce the 
	same hash code consistently.
	
	All objects in Java inherit a default implementation of hashCode() function defined in Object class. This function produces hash 
	code by typically converting the internal address of the object into an integer, thus producing different hash codes for all different 
	objects.
	
	Internally HashMap contains an array of Node and a node is represented as a class which contains 4 fields :

		int hash
		K key
		V value
		Node next	
 
  
  Performance of HashMap depends on 2 parameters :-

		Initial Capacity	- Capacity of HashMap when its created (16)
		Load Factor			- Measure that when rehashing should be done. Rehashing is the process to increasing the capacity. 
							- HashMap capacity is multiplied by 2.
							- Most generally preffered load factor value is 0.75 which provides a good deal between time and space costs. 
							- Load factor’s value varies between 0 and 1.
		
 
  Synchronized HashMap :-
 
 		Map m = Collections.synchronizedMap(new HashMap(...));
 	
  Time complexity of HashMap :-

		HashMap provides constant time complexity for basic operations, get and put.
		Iteration over HashMap depends on the capacity of HashMap and number of key-value pairs. 
		Basically it is directly proportional to the capacity + size. Capacity is the number of buckets in HashMap. 
		So it is not a good idea to keep high number of buckets in HashMap initially.
		
		
		
	HashMap improvements in Java 8
	===============================
	
	There is a performance improvement for HashMap objects where there are lots of collisions in the keys by using balanced trees rather 
	than linked lists to store map entries. 
	
	The principal idea is that once the number of items in a hash bucket grows beyond a certain threshold, that bucket will switch 
	from using a linked list of entries to a balanced tree. In the case of high hash collisions, this will improve worst-case 
	performance from O(n) to O(log n).
	
	
	Basically when a bucket becomes too big (currently: TREEIFY_THRESHOLD = 8), HashMap dynamically replaces it with an ad-hoc 
	implementation of the treemap. This way rather than having pessimistic O(n) we get much better O(log n).

	Bins (elements or nodes) of TreeNodes may be traversed and used like any others, but additionally support faster lookup when 
	overpopulated. However, since the vast majority of bins in normal use are not overpopulated, checking for the existence of tree bins 
	may be delayed in the course of table methods.

	Tree bins (i.e., bins whose elements are all TreeNodes) are ordered primarily by hashCode, but in the case of ties, if two elements 
	are of the same “class C implements Comparable<C>“, type then their compareTo() method is used for ordering.

	Because TreeNodes are about twice the size of regular nodes, we use them only when bins contain enough nodes. And when they become too 
	small (due to removal or resizing) they are converted back to plain bins (currently: UNTREEIFY_THRESHOLD = 6). In usages with
	well-distributed user hashCodes, tree bins are rarely used.
	
		